{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6244f984",
   "metadata": {
    "tags": []
   },
   "source": [
    "DRWI Pollution Assessment Stage 2  \n",
    "Notebook 1: Fecth Data\n",
    "===\n",
    "\n",
    "This first notebook fetches and prepares all the input data and modeling necessary for the Stage 2 Assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d094d8",
   "metadata": {},
   "source": [
    "# Installation and Setup\n",
    "\n",
    "Carefully follow our **[Installation Instructions](README.md#get-started)**, especially including:\n",
    "- Creating a virtual environment for this repository (step 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b2a24",
   "metadata": {},
   "source": [
    "## Import Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a593b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy     as np\n",
    "import pandas    as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# packages for data requests\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6317d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas:  0.10.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Geopandas: \", gpd.__version__)\n",
    "# print(\"spatialpandas: \", spd.__version__)\n",
    "# print(\"datashader: \", ds.__version__)\n",
    "# print(\"pygeos: \", pygeos.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95b6dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/aaufdenkampe/Documents/Python/pollution-assessment/stage2',\n",
       " '/Users/aaufdenkampe/opt/anaconda3/envs/drwi_pa/lib/python39.zip',\n",
       " '/Users/aaufdenkampe/opt/anaconda3/envs/drwi_pa/lib/python3.9',\n",
       " '/Users/aaufdenkampe/opt/anaconda3/envs/drwi_pa/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/aaufdenkampe/opt/anaconda3/envs/drwi_pa/lib/python3.9/site-packages',\n",
       " '/Users/aaufdenkampe/Documents/Python/pollution-assessment/src']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d894cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path exists, skipping /Users/aaufdenkampe/Documents/Python/pollution-assessment/src\n",
      "completed operation for: /Users/aaufdenkampe/Documents/Python/pollution-assessment/src\n"
     ]
    }
   ],
   "source": [
    "!conda-develop /Users/aaufdenkampe/Documents/Python/pollution-assessment/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4808fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for Pollution Assessment\n",
    "import pollution_assessment as pa\n",
    "import pollution_assessment.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8e05ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'plot']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the plot sub-module is imported\n",
    "dir(pa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139bc57",
   "metadata": {},
   "source": [
    "## Set Paths to Input and Output Files with `pathlib`\n",
    "\n",
    "Use the [pathlib](https://docs.python.org/3/library/pathlib.html) library (built-in to Python 3) to manage paths indpendentely of OS or environment.\n",
    "\n",
    "This blog post describes `pathlib`'s benefits relative to using the `os` library or manual approaches.\n",
    "- https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ea02c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/aaufdenkampe/Documents/Python/pollution-assessment/stage2')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find your current working directory, which should be folder for this notebook.\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f8fd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/aaufdenkampe/Documents/Python/pollution-assessment')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your project directory to your local folder for your clone of this repository\n",
    "project_path = Path.cwd().parent\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3da955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign relative paths for data folders. End with a slash character, `/`.\n",
    "pa1_data_folder = Path('stage1/data/')\n",
    "pa2_mmw_folder  = Path('stage2/DRB_GWLFE/mmw_results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9b9c2-f187-4364-b6ef-da5f5ff4de28",
   "metadata": {},
   "source": [
    "# Stage 2 Naming Conventions\n",
    "NOTE: we changed these slightly from Stage 1, to better facilitate building various options.\n",
    "\n",
    "Level 1 names, scale:\n",
    "* `catch` indicates catchment-level data, for the local catchment only\n",
    "* `reach` indicates reach-level data, which includes all upstream contributions\n",
    "\n",
    "Level 2 names, model:\n",
    "* `_base` indicates model baseline outputs (no conservation)\n",
    "* `_rest` indicates model with restoration reductions\n",
    "* `_prot` indicates model with protection projects, avoided loads\n",
    "\n",
    "**Clusters** are geographic units. There are 8 included in the DRB: Poconos-Kittaninny, Upper Lehigh,  New Jersey Highlands, Middle Schuylkill, Schuylkill Highlands, Upstream Suburban Philadelphia, Brandywine-Christina, Kirkwood-Cohansey Aquifer. These priority locations include parts of pristine headwaters and working forests of the upper watershed, farmlands, suburbs, and industrial and urban centers downstream, and the coastal plain where the river and emerging groundwater empties into either the Delaware Bay or the Atlantic Coast.\n",
    "\n",
    "**Focus areas** are smaller geographic units within clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc78e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read Input Data Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097498e",
   "metadata": {},
   "source": [
    "## Read Stage 1 Files for COMIDs & Geographies\n",
    "- Background: stage1/WikiSRAT_AnalysisViz.ipynb\n",
    "- Parquet to GeoDataFrame: https://geopandas.readthedocs.io/en/latest/docs/reference/api/geopandas.read_parquet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5f13b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 83.8 ms, total: 1.19 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read data from parquet files\n",
    "catch_base_gdf = gpd.read_parquet(project_path / pa1_data_folder /'base_df_catch.parquet')\n",
    "reach_base_gdf = gpd.read_parquet(project_path / pa1_data_folder /'base_df_reach.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d921eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 19496 entries, 1748535 to 932040370\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   tp_load             19496 non-null  float64 \n",
      " 1   tn_load             19496 non-null  float64 \n",
      " 2   tss_load            19496 non-null  float64 \n",
      " 3   catchment_hectares  19496 non-null  float64 \n",
      " 4   watershed_hectares  19496 non-null  float64 \n",
      " 5   tp_loadrate_ws      19496 non-null  float64 \n",
      " 6   tn_loadrate_ws      19496 non-null  float64 \n",
      " 7   tss_loadrate_ws     19496 non-null  float64 \n",
      " 8   maflowv             19496 non-null  float64 \n",
      " 9   geom_catchment      19496 non-null  geometry\n",
      " 10  cluster             17358 non-null  category\n",
      " 11  sub_focusarea       186 non-null    Int64   \n",
      " 12  nord                18870 non-null  Int64   \n",
      " 13  nordstop            18844 non-null  Int64   \n",
      " 14  huc12               19496 non-null  category\n",
      " 15  streamorder         19496 non-null  int64   \n",
      " 16  headwater           19496 non-null  int64   \n",
      " 17  phase               4082 non-null   category\n",
      " 18  fa_name             4082 non-null   category\n",
      "dtypes: Int64(3), category(4), float64(9), geometry(1), int64(2)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "catch_base_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "389622c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 19496 entries, 1748535 to 932040370\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   tp_conc             16823 non-null  float64 \n",
      " 1   tn_conc             16823 non-null  float64 \n",
      " 2   tss_conc            16823 non-null  float64 \n",
      " 3   catchment_hectares  19496 non-null  float64 \n",
      " 4   watershed_hectares  19496 non-null  float64 \n",
      " 5   maflowv             19496 non-null  float64 \n",
      " 6   geom                19494 non-null  geometry\n",
      " 7   cluster             17358 non-null  category\n",
      " 8   sub_focusarea       186 non-null    Int64   \n",
      " 9   nord                18870 non-null  Int64   \n",
      " 10  nordstop            18844 non-null  Int64   \n",
      " 11  huc12               19496 non-null  category\n",
      " 12  streamorder         19496 non-null  int64   \n",
      " 13  headwater           19496 non-null  int64   \n",
      " 14  phase               4082 non-null   category\n",
      " 15  fa_name             4082 non-null   category\n",
      "dtypes: Int64(3), category(4), float64(6), geometry(1), int64(2)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "reach_base_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5684b",
   "metadata": {},
   "source": [
    "### Remove Stage 1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b9fc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa1_catch_vars = ['tp_load', 'tn_load', 'tss_load',\n",
    "                  'tp_loadrate_ws', 'tn_loadrate_ws', 'tss_loadrate_ws',]\n",
    "catch_base_gdf.drop(pa1_catch_vars, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0a0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa1_reach_vars = ['tp_conc', 'tn_conc', 'tss_conc',]\n",
    "reach_base_gdf.drop(pa1_reach_vars, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de0076",
   "metadata": {},
   "source": [
    "## Read Stage 2 MMW Results\n",
    "- CSV to Pandas: \n",
    "  - Guide: https://pandas.pydata.org/docs/user_guide/io.html#csv-text-files \n",
    "  - Ref:   https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "### Correct WikiSRAT Names for Load Rate\n",
    "\n",
    "The WikiSRAT microservice output gives `tploadrate_total`, etc., which Sarah D. saved to the `catchment_load_rates.csv` file.\n",
    "\n",
    "This is a mistake, and it actually is the **local** NHDplus **catchment annual load (kg/ha)**. \n",
    "\n",
    "Mike suspected this error and we confirmed it during Stage 1 by comparing to Model My Watershed subbasin modeling output for specific COMDIDs.\n",
    "\n",
    "Upstream loads are not returned from WikiSRAT, although they are calculated internally to generate average annual stream reach concentrations.\n",
    "Upstream loads can therfore be calculated by dividing average anual concentrations (mg/L) by mean annual flow (cfs) to get (kg/y) (after including some unit conversions).\n",
    "\n",
    "### Units (Not Implemented)\n",
    "\n",
    "Loads are in kg/y.  \n",
    "Concentrations are in mg/L.\n",
    "\n",
    "From Mike:\n",
    "- `Loadrate_total_ws` was my attempt to get the loadrate totals to kg per hectare\n",
    "  - Fails if mean annual flow (`maflowv` (CFS)) doesnâ€™t exist (-9999).\n",
    "  - `loadrate_total_ws  = ((loadate_conc * 28.3168 * 31557600 / 1000000) * maflowv) / watershed_hectares`\n",
    "    - `31557600 = 365.25 * 24 * 60 * 60`\n",
    "    - 28.3168 liters in a cubic foot\n",
    "    - 1000000 mg in kg\n",
    "\n",
    "From: https://www.fws.gov/r5gomp/gom/nhd-gom/NHDPLUS_UserGuide.pdf\n",
    "> MAFlowV: Mean Annual Flow (cfs) at bottom of flowline as computed by Vogel Method\n",
    "\n",
    "**INCOMPLETE**\n",
    "\n",
    "Options for the future:\n",
    "- https://stackoverflow.com/questions/14688306/adding-meta-information-metadata-to-pandas-dataframe\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html\n",
    "- https://stackoverflow.com/questions/39419178/how-can-i-manage-units-in-pandas-data\n",
    "- https://github.com/hgrecco/pint\n",
    "- https://towardsdatascience.com/add-metadata-to-your-dataset-using-apache-parquet-75360d2073bd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375cb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wikisrat_catchment_loads = pd.read_csv(project_path / pa2_mmw_folder /\n",
    "                                            'catchment_loading_rates.csv',\n",
    "                                            index_col = 'comid',\n",
    "                                            dtype = {\n",
    "                                                'Source':'category',\n",
    "                                                'gwlfe_endpoint':'category',\n",
    "                                                'huc_run_name':'category',\n",
    "                                                'huc_run_states':'category',\n",
    "                                                'land_use_source':'category',\n",
    "                                                'closest_weather_stations':'category',\n",
    "                                                'stream_layer':'category',\n",
    "                                                'weather_source':'category',\n",
    "                                            }\n",
    "                                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51750a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21840 entries, 2612780 to 9891532\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   Unnamed: 0                21840 non-null  int64   \n",
      " 1   TotalN                    21840 non-null  float64 \n",
      " 2   TotalP                    21840 non-null  float64 \n",
      " 3   Sediment                  21840 non-null  float64 \n",
      " 4   gwlfe_endpoint            21840 non-null  category\n",
      " 5   huc                       21840 non-null  int64   \n",
      " 6   huc_level                 21840 non-null  int64   \n",
      " 7   huc_run                   21840 non-null  int64   \n",
      " 8   huc_run_level             21840 non-null  int64   \n",
      " 9   huc_run_name              21840 non-null  category\n",
      " 10  huc_run_states            21840 non-null  category\n",
      " 11  huc_run_areaacres         21840 non-null  float64 \n",
      " 12  land_use_source           21840 non-null  category\n",
      " 13  closest_weather_stations  21840 non-null  category\n",
      " 14  stream_layer              21840 non-null  category\n",
      " 15  weather_source            21840 non-null  category\n",
      "dtypes: category(7), float64(4), int64(5)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "wikisrat_catchment_load_rates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisrat_catchment_concs = pd.read_csv(project_path / pa2_mmw_folder /\n",
    "                                       'reach_concentrations.csv',\n",
    "                                       index_col = 'comid',\n",
    "                                       dtype = {\n",
    "                                           'Source':'category',\n",
    "                                           'gwlfe_endpoint':'category',\n",
    "                                           'huc_run_name':'category',\n",
    "                                           'huc_run_states':'category',\n",
    "                                           'land_use_source':'category',\n",
    "                                           'closest_weather_stations':'category',\n",
    "                                           'stream_layer':'category',\n",
    "                                           'weather_source':'category',\n",
    "                                       }\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd25a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21840 entries, 2612780 to 9891532\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   Unnamed: 0                21840 non-null  int64   \n",
      " 1   TotalN                    15834 non-null  float64 \n",
      " 2   TotalP                    15834 non-null  float64 \n",
      " 3   Sediment                  15834 non-null  float64 \n",
      " 4   gwlfe_endpoint            21840 non-null  category\n",
      " 5   huc                       21840 non-null  int64   \n",
      " 6   huc_level                 21840 non-null  int64   \n",
      " 7   huc_run                   21840 non-null  int64   \n",
      " 8   huc_run_level             21840 non-null  int64   \n",
      " 9   huc_run_name              21840 non-null  category\n",
      " 10  huc_run_states            21840 non-null  category\n",
      " 11  huc_run_areaacres         21840 non-null  float64 \n",
      " 12  land_use_source           21840 non-null  category\n",
      " 13  closest_weather_stations  21840 non-null  category\n",
      " 14  stream_layer              21840 non-null  category\n",
      " 15  weather_source            21840 non-null  category\n",
      "dtypes: category(7), float64(4), int64(5)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "wikisrat_catchment_concs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67448c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NASA_NLDAS_2000_2019', 'USEPA_1960_1990']\n",
       "Categories (2, object): ['NASA_NLDAS_2000_2019', 'USEPA_1960_1990']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore categoricals\n",
    "wikisrat_catchment_concs.weather_source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086db53",
   "metadata": {},
   "source": [
    "## Add Stage 2 data to Stage 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d524b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_catch_gdf['tp_load2'] = wikisrat_catchment_load_rates.TotalP\n",
    "base_catch_gdf['tn_load2'] = wikisrat_catchment_load_rates.TotalN\n",
    "base_catch_gdf['tss_load2'] = wikisrat_catchment_load_rates.Sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a803e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 19496 entries, 1748535 to 932040370\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   tp_load             19496 non-null  float64 \n",
      " 1   tn_load             19496 non-null  float64 \n",
      " 2   tss_load            19496 non-null  float64 \n",
      " 3   catchment_hectares  19496 non-null  float64 \n",
      " 4   watershed_hectares  19496 non-null  float64 \n",
      " 5   tp_loadrate_ws      19496 non-null  float64 \n",
      " 6   tn_loadrate_ws      19496 non-null  float64 \n",
      " 7   tss_loadrate_ws     19496 non-null  float64 \n",
      " 8   maflowv             19496 non-null  float64 \n",
      " 9   geom_catchment      19496 non-null  geometry\n",
      " 10  cluster             17358 non-null  category\n",
      " 11  sub_focusarea       186 non-null    Int64   \n",
      " 12  nord                18870 non-null  Int64   \n",
      " 13  nordstop            18844 non-null  Int64   \n",
      " 14  huc12               19496 non-null  category\n",
      " 15  streamorder         19496 non-null  int64   \n",
      " 16  headwater           19496 non-null  int64   \n",
      " 17  phase               4082 non-null   category\n",
      " 18  fa_name             4082 non-null   category\n",
      " 19  tp_load2            19496 non-null  float64 \n",
      " 20  tn_load2            19496 non-null  float64 \n",
      " 21  tss_load2           19496 non-null  float64 \n",
      "dtypes: Int64(3), category(4), float64(12), geometry(1), int64(2)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "base_catch_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fee80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_reach_gdf['tp_conc2'] = wikisrat_catchment_concs.TotalP\n",
    "base_reach_gdf['tn_conc2'] = wikisrat_catchment_concs.TotalN\n",
    "base_reach_gdf['tss_conc2'] = wikisrat_catchment_concs.Sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5214dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 19496 entries, 1748535 to 932040370\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   tp_conc             16823 non-null  float64 \n",
      " 1   tn_conc             16823 non-null  float64 \n",
      " 2   tss_conc            16823 non-null  float64 \n",
      " 3   catchment_hectares  19496 non-null  float64 \n",
      " 4   watershed_hectares  19496 non-null  float64 \n",
      " 5   maflowv             19496 non-null  float64 \n",
      " 6   geom                19494 non-null  geometry\n",
      " 7   cluster             17358 non-null  category\n",
      " 8   sub_focusarea       186 non-null    Int64   \n",
      " 9   nord                18870 non-null  Int64   \n",
      " 10  nordstop            18844 non-null  Int64   \n",
      " 11  huc12               19496 non-null  category\n",
      " 12  streamorder         19496 non-null  int64   \n",
      " 13  headwater           19496 non-null  int64   \n",
      " 14  phase               4082 non-null   category\n",
      " 15  fa_name             4082 non-null   category\n",
      " 16  tp_conc2            14712 non-null  float64 \n",
      " 17  tn_conc2            14712 non-null  float64 \n",
      " 18  tss_conc2           14712 non-null  float64 \n",
      "dtypes: Int64(3), category(4), float64(9), geometry(1), int64(2)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "base_reach_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abff2e",
   "metadata": {},
   "source": [
    "# Other stuff...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_sourc_df = pd.read_csv(mmw_data_folder /'wikisrat_catchment_sources.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f1cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read data from parquet files\n",
    "base_catch_gdf = gpd.read_parquet(data_folder /'base_df_catch.parquet')\n",
    "base_reach_gdf = gpd.read_parquet(data_folder /'base_df_reach.parquet')\n",
    "\n",
    "rest_catch_gdf = gpd.read_parquet(data_folder /'rest_df_catch.parquet')\n",
    "rest_reach_gdf = gpd.read_parquet(data_folder /'rest_df_reach.parquet')\n",
    "\n",
    "point_src_gdf = gpd.read_parquet(data_folder /'point_source_df.parquet')\n",
    "\n",
    "proj_prot_gdf = gpd.read_parquet(data_folder /'prot_proj_df.parquet')\n",
    "proj_rest_gdf = gpd.read_parquet(data_folder /'rest_proj_df.parquet')\n",
    "\n",
    "cluster_gdf = gpd.read_parquet(data_folder /'cluster_df.parquet')   \n",
    "\n",
    "mmw_huc12_loads_df = pd.read_parquet(data_folder /'mmw_huc12_loads_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e2fbcc-58b5-4ffc-b4e3-d0dc959dae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "focusarea_gdf = gpd.read_parquet(data_folder /'fa_phase2_df.parquet')\n",
    "focusarea_gdf.cluster = focusarea_gdf.cluster.replace('Kirkwood Cohansey Aquifer', 'Kirkwood - Cohansey Aquifer') # update name for consistency with other files \n",
    "focusarea_gdf.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d438e2-71b0-4eb5-b891-5c2b15a0c3f3",
   "metadata": {},
   "source": [
    "Follow this notebook with WikiSRAT_Analysis.ipynb for analysis of fetched data. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be2ad55ef110ae35ba44efbbda9909011312709cc16366f2adb735c9d7f96037"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('drwi_pa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
